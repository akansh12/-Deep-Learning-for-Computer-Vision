{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-791a48d972b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2,2, dtype = torch.int8)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dtype)\n",
    "x = x.type(torch.float)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dtype)\n",
    "y = x.numpy()\n",
    "print(y.dtype)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.from_numpy(y)\n",
    "print(z)\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "path2data = \"./data\"\n",
    "train_data = datasets.MNIST(path2data, train = True, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_data.data, train_data.targets\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "val_data = datasets.MNIST(path2data, train = False, download = True)\n",
    "x_val,y_val = val_data.data , val_data.targets\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "if len(x_train.shape) == 3:\n",
    "    x_train = x_train.unsqueeze(1)\n",
    "print(x_train.shape)\n",
    "\n",
    "if len(x_val.shape) == 3:\n",
    "    x_val = x_val.unsqueeze(1)\n",
    "print(x_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    npimg_tr = np.transpose(npimg, (1,2,0))\n",
    "    plt.imshow(npimg_tr, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b49be1a7f497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-e1656b292043>\u001b[0m in \u001b[0;36mshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnpimg_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "x_grid = utils.make_grid(x_train[:40], nrow= 8 , padding= 2)\n",
    "show(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomRotation((-30,30)),\n",
    "#     transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_data[0][0]\n",
    "img_tr = data_transform(img)\n",
    "\n",
    "img_tr = img_tr.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'transformed')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "plt.title(\"original\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img_tr[0], cmap = \"gray\")\n",
    "plt.title(\"transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(path2data, train = True, download = False, transform = data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_data.data, train_data.targets\n",
    "if len(x_train.shape) == 3:\n",
    "    x_train = x_train.unsqueeze(1)\n",
    "print(x_train.shape)\n",
    "\n",
    "if len(x_val.shape) == 3:\n",
    "    x_val = x_val.unsqueeze(1)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "val_ds = TensorDataset(x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_ds:\n",
    "    print(x.shape, y.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 28, 28])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_ds, batch_size = 8)\n",
    "val_dl = DataLoader(val_ds, batch_size = 8)\n",
    "\n",
    "for xb,yb in train_dl:\n",
    "    print(xb.shape)\n",
    "    print(yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4,5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5,1),\n",
    "\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,20,5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.fc1 = nn.Linear(4*4*50,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss(reduction= \"sum\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.57041931152344\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_dl:\n",
    "    xb = xb.type(torch.float).to(device)\n",
    "    yb = yb.to(device)\n",
    "    \n",
    "    out = model(xb)\n",
    "    loss = loss_func(out,yb)\n",
    "    print(loss.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "opt = optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()\n",
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(loss_func, xb, yb, yb_h, opt = None):\n",
    "    loss = loss_func(yb_h, yb)\n",
    "    metric_b = metric_batch(yb,yb_h)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), metric_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_batch(target, output):\n",
    "    pred = output.argmax(dim =1, keepdim = True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_epoch(model, loss_func, dataset_dl, opt = None):\n",
    "    loss = 0.0\n",
    "    metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "    for xb,yb in dataset_dl:\n",
    "        xb = xb.type(torch.float).to(device)\n",
    "        yb = yb.to(device)\n",
    "        yb_h = model(xb)\n",
    "        \n",
    "        loss_b, metric_b = loss_batch(loss_func, xb, yb, yb_h, opt)\n",
    "        \n",
    "        loss += loss_b\n",
    "        if metric_b is not None:\n",
    "            metric += metric_b\n",
    "   \n",
    "    loss /=len_data\n",
    "    metric /=len_data\n",
    "    \n",
    "    return loss, metric\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(epochs, model, loss_func, opt, train_dl, val_dl):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func = loss_func, dataset_dl = train_dl, opt = opt)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func = loss_func, dataset_dl = val_dl)\n",
    "            \n",
    "        accuracy = val_metric*100\n",
    "        \n",
    "        print(f\"Epoch:{epoch+1} , train_loss: {train_loss}, val_loss: {val_loss}, train_accuracy: {train_metric*100}, val_accuracy: {accuracy}\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 , train_loss: 0.14814061816236881, val_loss: 0.10432322685370164, train_accuracy: 95.8, val_accuracy: 96.44\n",
      "Epoch:2 , train_loss: 0.04696866674844446, val_loss: 0.05179334586981563, train_accuracy: 98.565, val_accuracy: 98.52\n",
      "Epoch:3 , train_loss: 0.026723440521855303, val_loss: 0.04774997621272404, train_accuracy: 99.175, val_accuracy: 98.67\n",
      "Epoch:4 , train_loss: 0.018559664947776458, val_loss: 0.06156008197265955, train_accuracy: 99.43833333333333, val_accuracy: 98.46000000000001\n",
      "Epoch:5 , train_loss: 0.013763859619872547, val_loss: 0.09979262275360448, train_accuracy: 99.56, val_accuracy: 98.07000000000001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "train_val(num_epochs, model.cuda(), loss_func, opt, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
