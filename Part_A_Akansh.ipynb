{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_A_Akansh.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1COpboboMjYFKQAfN3Rie4rSxnW5hMj9n",
      "authorship_tag": "ABX9TyMv6n4/g3sut7NtAZ3wjkMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akansh12/-Deep-Learning-for-Computer-Vision/blob/main/Part_A_Akansh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "bpsqz3GDsGAc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "metadata": {
        "id": "4LSedwiPtkjL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qurstion-1"
      ],
      "metadata": {
        "id": "YjdzUTcJtlJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### HELPER FUNCTIONS\n",
        "def findConv2dOutShape(H_in,W_in,conv,pool=2):\n",
        "  kernel_size=conv.kernel_size\n",
        "  stride=conv.stride\n",
        "  padding=conv.padding\n",
        "  dilation=conv.dilation\n",
        "\n",
        "  H_out=np.floor((H_in+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
        "  W_out=np.floor((W_in+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
        "  if pool:\n",
        "    H_out/=pool\n",
        "    W_out/=pool\n",
        "  return int(H_out),int(W_out)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = \"cpu\""
      ],
      "metadata": {
        "id": "Z8y2uPrRyIZb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_net(nn.Module):\n",
        "  def __init__(self, params): #num_filters, filter_size, activation_functions,dense_neurons,num_outputs\n",
        "    super(conv_net,self).__init__()\n",
        "    c_in, h_in, w_in = params[\"input_shape\"]\n",
        "    num_filters = params[\"num_filters\"]\n",
        "    filter_size = params[\"filter_size\"]\n",
        "    self.act_function = params[\"activation_functions\"]\n",
        "    dense_neurons = params[\"dense_neurons\"]\n",
        "    num_output = params[\"num_output\"]\n",
        "    self.dropout = params[\"dropout\"]\n",
        "\n",
        "\n",
        "    ####Conv layers\n",
        "    self.conv1 = nn.Conv2d(c_in, num_filters[0], kernel_size=filter_size[0])\n",
        "    h,w = findConv2dOutShape(h_in, w_in, self.conv1)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(num_filters[0], num_filters[1], kernel_size=filter_size[1])\n",
        "    h,w = findConv2dOutShape(h, w, self.conv2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(num_filters[1], num_filters[2], kernel_size=filter_size[2])\n",
        "    h,w = findConv2dOutShape(h, w, self.conv3)\n",
        "\n",
        "\n",
        "    self.conv4 = nn.Conv2d(num_filters[2], num_filters[3], kernel_size=filter_size[3])\n",
        "    h,w = findConv2dOutShape(h, w, self.conv4)\n",
        "\n",
        "\n",
        "    self.conv5 = nn.Conv2d(num_filters[3], num_filters[4], kernel_size=filter_size[4])\n",
        "    h,w = findConv2dOutShape(h, w, self.conv5)\n",
        "    #FC layers\n",
        "    self.num_flatten = h*w*num_filters[4]\n",
        "    self.fc1 = nn.Linear(self.num_flatten, dense_neurons)\n",
        "    self.fc2 = nn.Linear(dense_neurons, num_output)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.act_function[0](self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = self.act_function[1](self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = self.act_function[2](self.conv3(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = self.act_function[3](self.conv4(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = self.act_function[4](self.conv5(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    #Flatening the layers\n",
        "    x = x.view(-1, self.num_flatten)\n",
        "    \n",
        "    x = self.act_function[5](self.fc1(x))\n",
        "    x = F.dropout(x, self.dropout, training= self.training)\n",
        "    x = self.fc2(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    return x   \n"
      ],
      "metadata": {
        "id": "mMwQGRtrtjec"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"input_shape\": (3,224,224),\n",
        "          \"num_filters\": [8,16,32,64,128],\n",
        "          \"filter_size\":[3,3,3,3,3],\n",
        "          \"activation_functions\": [nn.functional.relu]*6,\n",
        "          \"dense_neurons\": 128,\n",
        "          \"num_output\":10,\n",
        "          \"dropout\": 0.2          \n",
        "          }"
      ],
      "metadata": {
        "id": "9x2I21oZ2ulR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = conv_net(params)\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "HVPLAUCSFt4n"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the total number of computations done by your network? (assume m filters in each layer of size k×k and n neurons in the dense layer)\n",
        "\n",
        "- Ans: \n",
        "\n",
        "2. What is the total number of parameters in your network? (assume m filters in each layer of size k×k and n neurons in the dense layer)\n",
        "\n",
        "- Ans: "
      ],
      "metadata": {
        "id": "XYiOmr9NGBGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2"
      ],
      "metadata": {
        "id": "7PKelzQjJxAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "path2data_train=\"/content/drive/MyDrive/Nature_data/inaturalist_12K/train\"\n",
        "path2data_test = \"/content/drive/MyDrive/Nature_data/inaturalist_12K/val\""
      ],
      "metadata": {
        "id": "uqgWVmTXJu9f"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import RandomRotation\n",
        "# DATA-Augmentations\n",
        "train_transforms = transforms.Compose([\n",
        "transforms.Resize((224,224)),\n",
        "transforms.RandomRotation((-20,20)),\n",
        "transforms.RandomHorizontalFlip(p=0.5),\n",
        "transforms.RandomVerticalFlip(p=0.5),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "transforms.Resize((224,224)),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ],
      "metadata": {
        "id": "a4xMupVOJvL5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.ImageFolder(path2data_train, train_transforms)\n",
        "test_data = datasets.ImageFolder(path2data_test, test_transforms)"
      ],
      "metadata": {
        "id": "QRNpSGS2NsaR"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEtK5bTBN7b5",
        "outputId": "5780296c-1a0d-43a7-c67f-a5e5658f1bde"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Amphibia': 0, 'Animalia': 1, 'Arachnida': 2, 'Aves': 3, 'Fungi': 4, 'Insecta': 5, 'Mammalia': 6, 'Mollusca': 7, 'Plantae': 8, 'Reptilia': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Spiliting the data into train-val\n",
        "n_val = int(np.floor(0.1 * len(data)))\n",
        "n_train = len(data) - n_val\n",
        "train_ds, val_ds = random_split(data, [n_train, n_val])"
      ],
      "metadata": {
        "id": "w6CbzaH-PRIi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of datapoints in train: \", len(train_ds))\n",
        "print(\"Number of datapoints in val: \", len(val_ds))\n",
        "print(\"Number of datapoints in test: \", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLHSpwEvPgSx",
        "outputId": "d7f1d2b9-3d2a-4358-a00a-e82a0b680817"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of datapoints in train:  9000\n",
            "Number of datapoints in val:  999\n",
            "Number of datapoints in test:  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
        "test_dl = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "_Qdn1Ks2OulG"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function\n",
        "loss_func = nn.NLLLoss(reduction=\"sum\")\n",
        "#optimizer\n",
        "from torch import optim\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "DD2gOOVSU0E1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Helper functions\n",
        "def metrics_b(out, y_true):\n",
        "  pred = out.argmax(dim=1, keepdim=True)\n",
        "  true_pred=pred.eq(y_true.view_as(pred)).sum().item()\n",
        "  return true_pred\n",
        "\n",
        "def loss_batch(loss_func, out, y_true, opt=None):\n",
        "  loss = loss_func(out, y_true)\n",
        "  metric_batch = metrics_b(out,y_true)\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  return loss.item(), metric_batch\n",
        "\n",
        "def loss_epoch(model,loss_func,data_loader,sanity_check=False,opt=None):\n",
        "  run_loss=0.0\n",
        "  running_metric=0.0\n",
        "  len_data=len(data_loader.dataset)\n",
        "  for x, y in data_loader:\n",
        "    x=x.to(device)\n",
        "    y=y.to(device)\n",
        "    output=model(x)\n",
        "    loss_b,metric_b=loss_batch(loss_func, output, y, opt)\n",
        "    run_loss+=loss_b\n",
        "\n",
        "    if metric_b is not None:\n",
        "      running_metric+=metric_b\n",
        "\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "\n",
        "  loss=run_loss/float(len_data)\n",
        "  metric=running_metric/float(len_data)\n",
        "\n",
        "  return loss, metric\n",
        "\n",
        "def train_val(model, params):\n",
        "  num_epochs=params[\"num_epochs\"]\n",
        "  loss_func=params[\"loss_func\"]\n",
        "  opt=params[\"optimizer\"]\n",
        "  train_dl=params[\"train_dl\"]\n",
        "  val_dl=params[\"val_dl\"]\n",
        "  sanity_check=params[\"sanity_check\"]\n",
        "  lr_scheduler=params[\"lr_scheduler\"]\n",
        "  path2weights=params[\"path2weights\"]\n",
        "\n",
        "  loss_hist={\n",
        "    \"train\": [],\n",
        "    \"val\": [],\n",
        "    }\n",
        "\n",
        "  metric_hist={\n",
        "    \"train\": [],\n",
        "    \"val\": [],\n",
        "    }\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss=float('inf')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs- 1))\n",
        "    model.train()\n",
        "    train_loss,train_metric=loss_epoch(model,loss_func,train_dl,sanity_check,opt)\n",
        "    loss_hist[\"train\"].append(train_loss)\n",
        "    metric_hist[\"train\"].append(train_metric)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss,val_metric = loss_epoch(model,loss_func,val_dl,sanity_check)\n",
        "      loss_hist[\"val\"].append(val_loss)\n",
        "      metric_hist[\"val\"].append(val_metric)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0yIIjoRSPoDo"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {\"num_epochs\": 30,\n",
        "                \"loss_func\": loss_func,\n",
        "                \"train_dl\":train_dl ,\n",
        "                \"val_dl\":val_dl, \n",
        "                \"test_dl\": test_dl,\n",
        "                \"path2weights\": \"./\"\n",
        "\n",
        "               }"
      ],
      "metadata": {
        "id": "TK4rWRwFVqCL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q-s4ak5_WrBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}